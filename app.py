import streamlit as st

# --- Arka plan rengini ayarla ---
def set_bg_color(color="#808080"):  
    st.markdown(
        f"""
        <style>
        .stApp {{
            background-color: {color};
        }}
        </style>
        """,
        unsafe_allow_html=True
    )

# Fonksiyonu Ã§aÄŸÄ±r
set_bg_color()


import streamlit as st
from pymilvus import connections, utility, Collection
from sentence_transformers import SentenceTransformer, util # type: ignore
import requests
import torch
import os
from dotenv import load_dotenv

load_dotenv()

API_KEY = os.getenv("API_KEY")
project_id = os.getenv("project_id")
MILVUS_HOST=os.getenv("MILVUS_HOST")
MILVUS_PORT=os.getenv("MILVUS_PORT")
MILVUS_USERNAME=os.getenv("MILVUS_USERNAME")
MILVUS_PASSWORD=os.getenv("MILVUS_PASSWORD")


# Milvus BaÄŸlantÄ±sÄ± (Sayfa yÃ¼klenirken bir kez baÄŸlan)
@st.cache_resource
def connect_milvus():
    connections.connect(host=MILVUS_HOST, port=MILVUS_PORT, secure=True, user=MILVUS_USERNAME, password=MILVUS_PASSWORD)

# IBM Token Alma
@st.cache_data
def get_ibm_token(API_KEY):
    headers = {'Content-Type': 'application/x-www-form-urlencoded'}
    data = f'grant_type=urn:ibm:params:oauth:grant-type:apikey&apikey={API_KEY}'

    response = requests.post('https://iam.cloud.ibm.com/identity/token', headers=headers, data=data)

    if response.status_code != 200:
        st.error("IBM Token alÄ±namadÄ±.")
        st.stop()

    return response.json()["access_token"]

# Milvus'ta Åirket Belirleme ve DokÃ¼man Arama
def classify_company(user_query):
    embeddings = model.encode([user_query] + company_list)
    query_embedding = embeddings[0]
    company_embeddings = embeddings[1:]

    cosine_scores = util.cos_sim(query_embedding, company_embeddings)

    best_score = cosine_scores.max().item()
    best_index = cosine_scores.argmax().item()

    if best_score > 0.7:
        return company_list[best_index]
    else:
        return None

def search_with_auto_classification(user_query):
    company_name = classify_company(user_query)
    
    if not company_name:
        return None, "Uygun bir ÅŸirket bulunamadÄ±. LÃ¼tfen daha aÃ§Ä±k bir ÅŸirket adÄ± belirtin."

    available_collections = utility.list_collections()
    collection_mapping = {
        "qnb": "wx_collection_qnb",
        "garanti": "wx_collection_garanti"
    }

    if company_name not in collection_mapping:
        return None, f"Collection mapping not found for {company_name}."

    target_collection = collection_mapping[company_name]

    if target_collection not in available_collections:
        return None, f"Collection '{target_collection}' not found in Milvus."

    collection = Collection(target_collection)
    query_vector = model.encode([user_query])
    search_params = {"metric_type": "L2", "params": {"nprobe": 10}}

    results = collection.search(
        data=query_vector,
        anns_field="vector",
        param=search_params,
        limit=3,
        output_fields=["document_name", "text"]
    )

    matched_docs = []
    for hits in results:
        for hit in hits:
            matched_docs.append({
                "score": hit.distance,
                "title": hit.entity.get("document_name"),
                "content": hit.entity.get("text")
            })

    return matched_docs, None

def route_to_agent(user_query, ibm_token, project_id):
    url = "https://us-south.ml.cloud.ibm.com/ml/v1/text/chat?version=2023-05-29"

    routing_prompt = (
        "AÅŸaÄŸÄ±daki kullanÄ±cÄ± sorusu hangi analiz tÃ¼rÃ¼ne giriyor? "
        "Sadece aÅŸaÄŸÄ±daki seÃ§eneklerden birini **tek kelime olarak** cevapla:\n"
        "- bÃ¼yÃ¼me\n"
        "- pazar\n"
        "- sÄ±ralama\n"
        "- stage\n"
        "- bilanÃ§o aktif\n"
        "- bilanÃ§o pasif\n"
        "- karzarar\n"
        "- genel\n\n"
        f"Soru: {user_query}"
    )


    messages = [
        {"role": "system", "content": "Sen bir sÄ±nÄ±flandÄ±rma ajanÄ±sÄ±n. Verilen soruyu yukarÄ±daki kategorilere gÃ¶re etiketle."},
        {"role": "user", "content": routing_prompt}
    ]

    body = {
        "messages": messages,
        "project_id": project_id,
        "model_id": "mistralai/mistral-large",
        "frequency_penalty": 0,
        "max_tokens": 100,
        "presence_penalty": 0,
        "temperature": 0,
        "top_p": 1
    }

    headers = {
        "Accept": "application/json",
        "Content-Type": "application/json",
        "Authorization": f"Bearer {ibm_token}" 
    }

    response = requests.post(url, headers=headers, json=body)

    if response.status_code != 200:
        st.error("Routing iÃ§in LLM yanÄ±tÄ± alÄ±namadÄ±.")
        st.stop()

    content = response.json()["choices"][0]["message"]["content"].strip().lower()
    return content


def generate_llm_response_with_routing(user_query, context, project_id, ibm_token):
    # ğŸ”¹ URL tanÄ±mlanÄ±yor
    url = "https://us-south.ml.cloud.ibm.com/ml/v1/text/chat?version=2023-05-29"
    # ğŸ”¹ Analiz tipini belirle (routing)
    agent_type = route_to_agent(user_query, ibm_token, project_id)

    # ğŸ”¹ GeliÅŸmiÅŸ prompt seti
    prompt_map = {
        "bÃ¼yÃ¼me": (
            "Sen bir finansal bÃ¼yÃ¼me analistisin. Net kÃ¢r Ã¼zerinden yÄ±llÄ±k (YoY) ve Ã§eyreklik (QoQ) bÃ¼yÃ¼me oranlarÄ±nÄ± "
            "hem oran (%) hem de tutar (milyon TL) olarak hesapla ve gÃ¶ster. Tablo formatÄ±nda sun. Soru iÃ§inde dÃ¶nem bilgisi verilmemiÅŸse, en gÃ¼ncel (son aÃ§Ä±klanan) dÃ¶nemin "
            "verilerini kullan."
        ),
        "pazar": (
            "Sen bankacÄ±lÄ±k pazar payÄ± uzmanÄ±sÄ±n. Kredilerde (tÃ¼ketici/ticari, TL/YP), mevduatta (vadeli/vadesiz, TL/YP) "
            "pazar paylarÄ±nÄ± ayrÄ±ntÄ±lÄ± ÅŸekilde analiz et. Tablo biÃ§iminde ve sade bir sunum yap.Soru iÃ§inde dÃ¶nem bilgisi verilmemiÅŸse, en gÃ¼ncel (son aÃ§Ä±klanan) dÃ¶nemin "
            "verilerini kullan."
        ),
        "sÄ±ralama": (
            "Sen finansal sÄ±ralama analistisin. BankalarÄ± aktif bÃ¼yÃ¼klÃ¼k, net kÃ¢r/zarar, toplam kredi ve toplam mevduat "
            "gibi kriterlere gÃ¶re sÄ±rala. En gÃ¼ncel verilere gÃ¶re tabloyla sun."
        ),
        "stage": (
            "Sen canlÄ± kredi izleme uzmanÄ±sÄ±sÄ±n.Sadece 'Birinci ve ikinci aÅŸama krediler' veya ' Standart Nitelikli ve YakÄ±n Ä°zlemedeki krediler ile yeniden yapÄ±landÄ±rÄ±lan YakÄ±n Ä°zlemedeki kredilere iliÅŸkin bilgiler' baÅŸlÄ±ÄŸÄ± altÄ±nda olan tÃ¼m tablolarÄ±n toplam deÄŸerlerini TL ve YP olarak ayrÄ± ayrÄ± getir. Soru iÃ§inde dÃ¶nem bilgisi verilmemiÅŸse, en gÃ¼ncel (son aÃ§Ä±klanan) dÃ¶nemin verilerini kullan."
        ),
        "genel": (
            "Sen bankacÄ±lÄ±k verilerini analiz eden bir asistanÄ±sÄ±n. KullanÄ±cÄ± sorusuna gÃ¶re sadece gerekli cevabÄ± ver.Soru iÃ§inde dÃ¶nem bilgisi verilmemiÅŸse, en gÃ¼ncel (son aÃ§Ä±klanan) dÃ¶nemin "
            "verilerini kullan."
        ),
        "bilanÃ§o aktif":("Sen bilanÃ§o aktif tablosu Ã¶zelinde Ã§alÄ±ÅŸan bir asistanÄ±sÄ±n. Sorulan soru eÄŸer 'BilanÃ§o Aktif' veya 'BilanÃ§o VarlÄ±klar' ile ilgiliyse Cari DÃ¶nem ve Ã–nceki DÃ¶nem iÃ§in ayrÄ± ayrÄ± TP, YP ve TOPLAM ÅŸeklinde ifade edilmiÅŸ durumdadÄ±r. Bu bilgileri TABLO iÃ§erisinde eksiksiz getireceksin.Soru iÃ§inde dÃ¶nem bilgisi verilmemiÅŸse, en gÃ¼ncel (son aÃ§Ä±klanan) dÃ¶nemin "
            "verilerini kullan."),
        "bilanÃ§o pasif":("Sen bilanÃ§o pasif tablosu Ã¶zelinde Ã§alÄ±ÅŸan bir asistanÄ±sÄ±n. Sorulan soru eÄŸer 'BilanÃ§o Pasif' veya 'BilanÃ§o YÃ¼kÃ¼mlÃ¼lÃ¼kler' ile ilgiliyse Cari DÃ¶nem ve Ã–nceki DÃ¶nem iÃ§in ayrÄ± ayrÄ± TP, YP ve TOPLAM ÅŸeklinde ifade edilmiÅŸ durumdadÄ±r. Bu bilgileri TABLO iÃ§erisinde eksiksiz getireceksin.Soru iÃ§inde dÃ¶nem bilgisi verilmemiÅŸse, en gÃ¼ncel (son aÃ§Ä±klanan) dÃ¶nemin "
            "verilerini kullan."),
        "karzarar":("Sen Kar veya Zarar Tablosu tablosu Ã¶zelinde Ã§alÄ±ÅŸan bir asistanÄ±sÄ±n. Sorulan soru eÄŸer 'Kar veya Zarar Tablosu' ile ilgiliyse Cari DÃ¶nem ve Ã–nceki DÃ¶nem iÃ§in ayrÄ± ayrÄ± TP, YP ve TOPLAM ÅŸeklinde ifade edilmiÅŸ durumdadÄ±r. Bu bilgileri TABLO iÃ§erisinde eksiksiz getireceksin.Soru iÃ§inde dÃ¶nem bilgisi verilmemiÅŸse, en gÃ¼ncel (son aÃ§Ä±klanan) dÃ¶nemin "
            "verilerini kullan.")
    }

    # ğŸ”¹ Prompta karar ver
    system_prompt = prompt_map.get(agent_type, prompt_map["genel"])

    # ğŸ”¹ DokÃ¼manlarÄ± metne Ã§evir
    context_text = "\n\n".join([
        f"Belge: {doc['title']}\nÄ°Ã§erik: {doc['content']}" for doc in context
    ])

    # ğŸ”¹ LLM mesajlarÄ±
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"KullanÄ±cÄ± sorusu: {user_query}\n\nÄ°lgili belgeler:\n{context_text}"}
    ]

    body = {
        "messages": messages,
        "project_id": project_id,
        "model_id": "mistralai/mistral-large",
        "frequency_penalty": 0,
        "max_tokens": 6000,
        "presence_penalty": 0,
        "temperature": 0,
        "top_p": 1
    }

    headers = {
        "Accept": "application/json",
        "Content-Type": "application/json",
        "Authorization": f"Bearer {ibm_token}"
    }

    # ğŸ”¹ POST isteÄŸi
    response = requests.post(url, headers=headers, json=body)

    if response.status_code != 200:
        st.error("LLM yanÄ±t alÄ±namadÄ±.")
        st.stop()

    return response.json()


# Uygulama BaÅŸlangÄ±cÄ±
st.set_page_config(page_title="Milvus + LLM Chat", page_icon="ğŸ¤–")

st.markdown(
    """
    <div style="display: flex; align-items: center;">
        <img src="https://upload.wikimedia.org/wikipedia/commons/9/95/TEB_LOGO.png" alt="Logo" width="120" style="margin-right:10px;">
    </div>
    """,
    unsafe_allow_html=True
)
st.title("CepTEBot")

connect_milvus()


import torch

device = "cuda" if torch.cuda.is_available() else "cpu"
# Model ve Åirketler
model = SentenceTransformer(
    "intfloat/multilingual-e5-large", device=device)
company_list = ["qnb", "garanti"]

# IBM API Key ve Project ID
#api_key = st.secrets["IBM_API_KEY"]  # streamlit secrets kullanÄ±labilir
#project_id = st.secrets["PROJECT_ID"]

user_query = st.text_input("LÃ¼tfen sorunuz:")

if st.button("Sorgula") and user_query.strip() != "":
    with st.spinner("Milvus'tan dokÃ¼man aranÄ±yor..."):
        docs, error = search_with_auto_classification(user_query)

    if error:
        st.error(error)
    elif not docs:
        st.warning("EÅŸleÅŸen dokÃ¼man bulunamadÄ±.")
    else:
        st.success("Ä°lgili dokÃ¼manlar bulundu!")
        with st.spinner("LLM routing yapÄ±lÄ±yor..."):
            ibm_token = get_ibm_token(API_KEY)
            llm_response = generate_llm_response_with_routing(user_query, docs, project_id, ibm_token)
        
        st.subheader("ğŸ’¬ LLM YanÄ±tÄ±")
        st.write(llm_response["choices"][0]["message"]["content"])
        


